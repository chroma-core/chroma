//! Load Generator Example
//!
//! A load generator for Chroma that creates concurrent upsert operations across multiple
//! collections on two different Chroma endpoints.
//!
//! # Features
//!
//! - Dual endpoint support (api.trychroma.com and europe-west1.gcp.devchroma.com)
//! - Configurable number of collections, tasks, batch size, and duration
//! - Random collection selection within each task to avoid concurrency hotspots
//! - Gaussian Mixture Model (GMM) for realistic embedding generation
//!
//! # Usage
//!
//! ```bash
//! cargo run --example load_generator_pointed -- --duration 600 --tasks 4 --batch-size 100
//! ```
//!
//! # Environment Variables
//!
//! The following environment variables must be set:
//! - `CHROMA_API_KEY` - API key for Chroma Cloud authentication
//! - `CHROMA_TENANT` - Tenant ID (optional, will be auto-resolved)
//! - `CHROMA_DATABASE` - Database name (optional, will be auto-resolved)

use std::sync::atomic::{AtomicBool, AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant, SystemTime};

use biometrics::{Collector, Counter};
use chroma::client::ChromaHttpClientOptions;
use chroma::ChromaCollection;
use chroma::ChromaHttpClient;
use clap::Parser;
use rand::rngs::StdRng;
use rand::{Rng, SeedableRng};
use tokio::sync::{mpsc, Mutex, Semaphore};

static UPSERT_LATENCY_US: sig_fig_histogram::LockFreeHistogram<450> =
    sig_fig_histogram::LockFreeHistogram::new(2);
static UPSERT_LATENCY_US_SENSOR: biometrics::Histogram =
    biometrics::Histogram::new("upsert.latency_ms.us", &UPSERT_LATENCY_US);

static UPSERT_LATENCY_EU: sig_fig_histogram::LockFreeHistogram<450> =
    sig_fig_histogram::LockFreeHistogram::new(2);
static UPSERT_LATENCY_EU_SENSOR: biometrics::Histogram =
    biometrics::Histogram::new("upsert.latency_ms.eu", &UPSERT_LATENCY_EU);

static UPSERT_SUCCESS_US: Counter = Counter::new("upsert.success.us");
static UPSERT_FAILURE_US: Counter = Counter::new("upsert.failure.us");
static UPSERT_SUCCESS_EU: Counter = Counter::new("upsert.success.eu");
static UPSERT_FAILURE_EU: Counter = Counter::new("upsert.failure.eu");

/// Default embedding dimension for the GMM.
const EMBEDDING_DIM: usize = 1536;

/// Number of clusters in the Gaussian Mixture Model.
const NUM_CLUSTERS: usize = 1000;

/// Gaussian Mixture Model for generating realistic embeddings.
///
/// The model consists of cluster centroids and covariance parameters.
/// Embeddings are generated by sampling from a randomly selected cluster.
struct GaussianMixtureModel {
    /// Cluster centroids, each of dimension EMBEDDING_DIM.
    centroids: Vec<Vec<f32>>,
    /// Standard deviation for each cluster.
    std_devs: Vec<f32>,
}

impl GaussianMixtureModel {
    /// Creates a new Gaussian Mixture Model with the specified parameters.
    ///
    /// The model is initialized with randomly placed centroids and varying
    /// standard deviations to create a diverse embedding space.
    fn new(seed: u64) -> Self {
        let mut rng = StdRng::seed_from_u64(seed);

        // Generate cluster centroids
        let centroids: Vec<Vec<f32>> = (0..NUM_CLUSTERS)
            .map(|_| {
                (0..EMBEDDING_DIM)
                    .map(|_| rng.gen_range(-1.0..1.0))
                    .collect()
            })
            .collect();

        // Generate varying standard deviations for each cluster
        let std_devs: Vec<f32> = (0..NUM_CLUSTERS)
            .map(|_| rng.gen_range(0.01..0.1))
            .collect();

        Self {
            centroids,
            std_devs,
        }
    }

    /// Generates a batch of embeddings by sampling from the mixture model.
    fn generate_batch(&self, rng: &mut StdRng, batch_size: usize) -> Vec<Vec<f32>> {
        (0..batch_size)
            .map(|_| {
                // Select a random cluster
                let cluster_idx = rng.gen_range(0..NUM_CLUSTERS);
                let centroid = &self.centroids[cluster_idx];
                let std_dev = self.std_devs[cluster_idx];

                // Sample from the cluster using Box-Muller transform for Gaussian noise
                centroid
                    .iter()
                    .map(|&c| {
                        let u1: f32 = rng.gen_range(0.0001..1.0);
                        let u2: f32 = rng.gen_range(0.0..1.0);
                        let z = (-2.0 * u1.ln()).sqrt() * (2.0 * std::f32::consts::PI * u2).cos();
                        c + z * std_dev
                    })
                    .collect()
            })
            .collect()
    }
}

/// Load generator for Chroma that creates concurrent upsert operations.
#[derive(Parser, Debug)]
#[command(name = "load_generator")]
#[command(about = "Generate load against Chroma endpoints")]
struct Args {
    /// Duration to run the load generator in seconds.
    #[arg(short, long, default_value_t = 600)]
    duration: u64,

    /// Number of concurrent tasks.
    #[arg(short, long, default_value_t = 4)]
    tasks: usize,

    /// Batch size for upsert operations.
    #[arg(short, long, default_value_t = 100)]
    batch_size: usize,

    /// Target request pace in queries per second.
    #[arg(long, default_value_t = 100)]
    pace_qps: u64,

    /// Maximum number of outstanding operations per collection.
    #[arg(long, default_value_t = 10)]
    max_outstanding_ops: usize,
}

/// Statistics tracking for a single backend.
struct BackendStats {
    /// Total number of successful upsert operations.
    total_upserts: AtomicU64,
    /// Total number of records upserted.
    total_records: AtomicU64,
}

impl BackendStats {
    /// Creates a new BackendStats instance.
    fn new() -> Self {
        Self {
            total_upserts: AtomicU64::new(0),
            total_records: AtomicU64::new(0),
        }
    }

    /// Records a successful upsert operation.
    fn record_upsert(&self, batch_size: u64) {
        self.total_upserts.fetch_add(1, Ordering::Relaxed);
        self.total_records.fetch_add(batch_size, Ordering::Relaxed);
    }

    /// Returns the current upsert count.
    fn upserts(&self) -> u64 {
        self.total_upserts.load(Ordering::Relaxed)
    }

    /// Returns the current record count.
    fn records(&self) -> u64 {
        self.total_records.load(Ordering::Relaxed)
    }
}

/// Shared state for worker tasks.
struct WorkerContext {
    gmm: Arc<GaussianMixtureModel>,
    stats: Arc<BackendStats>,
    batch_size: usize,
    start_time: Instant,
    duration: Duration,
    pacing_rx: Arc<Mutex<mpsc::Receiver<()>>>,
    latency_sensor: &'static biometrics::Histogram,
    success_counter: &'static Counter,
    failure_counter: &'static Counter,
}

/// Creates a client with the specified base URL, using credentials from environment.
fn create_client(base_url: &str) -> Result<ChromaHttpClient, Box<dyn std::error::Error>> {
    let mut options = ChromaHttpClientOptions::from_cloud_env()?;
    options.endpoint = base_url.parse()?;
    Ok(ChromaHttpClient::new(options))
}

/// Generates a deterministic collection name from the index.
fn collection_name() -> String {
    "loadgen_collection_pointed".to_string()
}

/// Maximum number of retry attempts for collection creation.
const MAX_COLLECTION_RETRIES: u32 = 3;

/// Creates or gets a collection with retry logic.
async fn get_or_create_collection_with_retry(
    client: &ChromaHttpClient,
    name: String,
) -> Result<ChromaCollection, chroma::client::ChromaHttpClientError> {
    let mut last_error = None;
    for attempt in 1..=MAX_COLLECTION_RETRIES {
        match client.get_or_create_collection(&name, None, None).await {
            Ok(collection) => return Ok(collection),
            Err(e) => {
                eprintln!(
                    "  Attempt {}/{} failed for collection '{}': {}",
                    attempt, MAX_COLLECTION_RETRIES, name, e
                );
                last_error = Some(e);
                if attempt < MAX_COLLECTION_RETRIES {
                    tokio::time::sleep(Duration::from_millis(500 * attempt as u64)).await;
                }
            }
        }
    }
    Err(last_error.unwrap())
}

/// Runs a worker task that performs upserts with random collection selection.
async fn run_worker(
    collections: Vec<ChromaCollection>,
    collection_semaphores: Vec<Arc<Semaphore>>,
    ctx: WorkerContext,
    seed: u64,
    id_prefix: String,
) {
    let mut rng = StdRng::seed_from_u64(seed);
    let mut record_counter: u64 = 0;
    let num_collections = collections.len();

    while ctx.start_time.elapsed() < ctx.duration {
        let remaining = ctx.duration.saturating_sub(ctx.start_time.elapsed());
        if remaining.is_zero() {
            break;
        }

        let ticket = tokio::time::timeout(remaining, async {
            let mut rx = ctx.pacing_rx.lock().await;
            rx.recv().await
        })
        .await;

        match ticket {
            Ok(Some(())) => {}
            _ => break,
        }

        // Random collection selection to avoid concurrency hotspots
        let collection_idx = rng.gen_range(0..num_collections);
        let collection = &collections[collection_idx];
        let semaphore = &collection_semaphores[collection_idx];

        // Acquire permit to limit outstanding ops per collection
        let permit = match semaphore.clone().acquire_owned().await {
            Ok(permit) => permit,
            Err(_) => break,
        };

        // Generate batch
        let embeddings = ctx.gmm.generate_batch(&mut rng, ctx.batch_size);
        let ids: Vec<String> = (0..ctx.batch_size)
            .map(|i| {
                record_counter += 1;
                format!("{}_{}", id_prefix, record_counter + i as u64)
            })
            .collect();

        // Perform upsert
        let upsert_start = Instant::now();
        match collection.upsert(ids, embeddings, None, None, None).await {
            Ok(_) => {
                ctx.latency_sensor
                    .observe(upsert_start.elapsed().as_secs_f64() * 1_000.0);
                ctx.success_counter.click();
                ctx.stats.record_upsert(ctx.batch_size as u64);
            }
            Err(e) => {
                ctx.latency_sensor
                    .observe(upsert_start.elapsed().as_secs_f64() * 1_000.0);
                ctx.failure_counter.click();
                eprintln!("[{}] Upsert error: {}", id_prefix, e);
            }
        }

        // Permit is dropped here, releasing the semaphore slot
        drop(permit);
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let args = Args::parse();

    println!("=== Chroma Load Generator ===");
    println!("Collection: {}", collection_name());
    println!("Duration: {} seconds", args.duration);
    println!("Tasks: {}", args.tasks);
    println!("Batch size: {}", args.batch_size);
    println!("Pace: {} qps", args.pace_qps.max(1));
    println!(
        "Max outstanding ops per collection: {}",
        args.max_outstanding_ops
    );
    println!();

    // Create clients for both endpoints.
    let client_us = create_client("https://api.devchroma.com:443")?;
    let client_eu = create_client("https://europe-west1.gcp.devchroma.com:443")?;

    println!("Creating/getting collection on both endpoints...",);

    // Load the collections for both endpoints.
    let collection_us = get_or_create_collection_with_retry(&client_us, collection_name()).await?;
    let collection_eu = get_or_create_collection_with_retry(&client_eu, collection_name()).await?;
    println!("Collections ready. Starting load generation...\n");

    // Set up biometrics collector and emitter for latency histograms
    let collector = Collector::new();
    collector.register_histogram(&UPSERT_LATENCY_US_SENSOR);
    collector.register_histogram(&UPSERT_LATENCY_EU_SENSOR);
    collector.register_counter(&UPSERT_SUCCESS_US);
    collector.register_counter(&UPSERT_FAILURE_US);
    collector.register_counter(&UPSERT_SUCCESS_EU);
    collector.register_counter(&UPSERT_FAILURE_EU);
    let done = Arc::new(AtomicBool::new(false));
    let done_emitter = Arc::clone(&done);
    let emitter_handle = std::thread::spawn(move || {
        let mut emitter = biometrics_prometheus::Emitter::new(biometrics_prometheus::Options {
            segment_size: 64 * 1024 * 1024 * 1024,
            flush_interval: Duration::from_secs(86_400),
            prefix: utf8path::Path::new("load-generator-pointed."),
        });
        let mut target = Instant::now() + Duration::from_secs(30);
        while !done_emitter.load(Ordering::Relaxed) {
            let now = Instant::now();
            if now < target {
                if let Some(wait) = target.checked_duration_since(now) {
                    std::thread::sleep(wait);
                }
            }
            target += Duration::from_secs(30);
            collector
                .emit(
                    &mut emitter,
                    SystemTime::now()
                        .duration_since(SystemTime::UNIX_EPOCH)
                        .expect("system time before UNIX epoch")
                        .as_millis()
                        .try_into()
                        .expect("timestamp overflow"),
                )
                .unwrap();
        }
    });

    // Create per-collection semaphores to limit outstanding operations
    let semaphores_us: Vec<Arc<Semaphore>> = (0..1)
        .map(|_| Arc::new(Semaphore::new(args.max_outstanding_ops)))
        .collect();
    let semaphores_eu: Vec<Arc<Semaphore>> = (0..1)
        .map(|_| Arc::new(Semaphore::new(args.max_outstanding_ops)))
        .collect();

    // Shared state
    let gmm = Arc::new(GaussianMixtureModel::new(42));
    let stats_us = Arc::new(BackendStats::new());
    let stats_eu = Arc::new(BackendStats::new());

    let start_time = Instant::now();
    let duration = Duration::from_secs(args.duration);
    let pace_qps = args.pace_qps.max(1);
    let ticket_interval = Duration::from_secs_f64(1.0 / pace_qps as f64);

    let (ticket_tx, ticket_rx) = mpsc::channel::<()>(1024);
    let pacing_rx = Arc::new(Mutex::new(ticket_rx));

    let pacing_handle = tokio::spawn(async move {
        let mut interval = tokio::time::interval(ticket_interval);
        while start_time.elapsed() < duration {
            interval.tick().await;
            let _ = ticket_tx.try_send(());
        }
    });

    // Spawn worker tasks
    let mut handles = Vec::new();

    for task_id in 0..args.tasks {
        // US endpoint task
        let ctx = WorkerContext {
            gmm: Arc::clone(&gmm),
            stats: Arc::clone(&stats_us),
            batch_size: args.batch_size,
            start_time,
            duration,
            pacing_rx: Arc::clone(&pacing_rx),
            latency_sensor: &UPSERT_LATENCY_US_SENSOR,
            success_counter: &UPSERT_SUCCESS_US,
            failure_counter: &UPSERT_FAILURE_US,
        };
        let handle = tokio::spawn(run_worker(
            vec![collection_us.clone()],
            semaphores_us.clone(),
            ctx,
            task_id as u64 * 1000,
            format!("us_task{}", task_id),
        ));
        handles.push(handle);

        // EU endpoint task
        let ctx = WorkerContext {
            gmm: Arc::clone(&gmm),
            stats: Arc::clone(&stats_eu),
            batch_size: args.batch_size,
            start_time,
            duration,
            pacing_rx: Arc::clone(&pacing_rx),
            latency_sensor: &UPSERT_LATENCY_EU_SENSOR,
            success_counter: &UPSERT_SUCCESS_EU,
            failure_counter: &UPSERT_FAILURE_EU,
        };
        let handle = tokio::spawn(run_worker(
            vec![collection_eu.clone()],
            semaphores_eu.clone(),
            ctx,
            (task_id as u64 + 500) * 1000,
            format!("eu_task{}", task_id),
        ));
        handles.push(handle);
    }

    // Progress reporting task
    let stats_us_report = Arc::clone(&stats_us);
    let stats_eu_report = Arc::clone(&stats_eu);
    let report_handle = tokio::spawn(async move {
        let mut last_us_upserts = 0u64;
        let mut last_us_records = 0u64;
        let mut last_eu_upserts = 0u64;
        let mut last_eu_records = 0u64;
        let report_interval = Duration::from_secs(10);

        while start_time.elapsed() < duration {
            tokio::time::sleep(report_interval).await;

            let us_upserts = stats_us_report.upserts();
            let us_records = stats_us_report.records();
            let eu_upserts = stats_eu_report.upserts();
            let eu_records = stats_eu_report.records();
            let elapsed = start_time.elapsed().as_secs_f64();

            let us_upserts_delta = us_upserts - last_us_upserts;
            let us_records_delta = us_records - last_us_records;
            let eu_upserts_delta = eu_upserts - last_eu_upserts;
            let eu_records_delta = eu_records - last_eu_records;

            let interval_secs = report_interval.as_secs_f64();

            println!(
                "[{:.0}s] US: {} upserts, {} records | Rate: {:.1} upserts/s, {:.1} records/s",
                elapsed,
                us_upserts,
                us_records,
                us_upserts_delta as f64 / interval_secs,
                us_records_delta as f64 / interval_secs
            );
            println!(
                "[{:.0}s] EU: {} upserts, {} records | Rate: {:.1} upserts/s, {:.1} records/s",
                elapsed,
                eu_upserts,
                eu_records,
                eu_upserts_delta as f64 / interval_secs,
                eu_records_delta as f64 / interval_secs
            );
            println!(
                "[{:.0}s] Total: {} upserts, {} records | Rate: {:.1} upserts/s, {:.1} records/s",
                elapsed,
                us_upserts + eu_upserts,
                us_records + eu_records,
                (us_upserts_delta + eu_upserts_delta) as f64 / interval_secs,
                (us_records_delta + eu_records_delta) as f64 / interval_secs
            );
            println!();

            last_us_upserts = us_upserts;
            last_us_records = us_records;
            last_eu_upserts = eu_upserts;
            last_eu_records = eu_records;
        }
    });

    // Wait for all tasks to complete
    for handle in handles {
        let _ = handle.await;
    }
    report_handle.abort();
    pacing_handle.abort();
    done.store(true, Ordering::Relaxed);
    emitter_handle.join().unwrap();

    let elapsed = start_time.elapsed();
    let elapsed_secs = elapsed.as_secs_f64();

    let us_upserts = stats_us.upserts();
    let us_records = stats_us.records();
    let eu_upserts = stats_eu.upserts();
    let eu_records = stats_eu.records();

    println!("\n=== Load Generation Complete ===");
    println!("Duration: {:.1} seconds", elapsed_secs);
    println!();
    println!("US Backend:");
    println!("  Total upserts: {}", us_upserts);
    println!("  Total records: {}", us_records);
    println!(
        "  Average rate: {:.1} upserts/s, {:.1} records/s",
        us_upserts as f64 / elapsed_secs,
        us_records as f64 / elapsed_secs
    );
    println!();
    println!("EU Backend:");
    println!("  Total upserts: {}", eu_upserts);
    println!("  Total records: {}", eu_records);
    println!(
        "  Average rate: {:.1} upserts/s, {:.1} records/s",
        eu_upserts as f64 / elapsed_secs,
        eu_records as f64 / elapsed_secs
    );
    println!();
    println!("Combined:");
    println!("  Total upserts: {}", us_upserts + eu_upserts);
    println!("  Total records: {}", us_records + eu_records);
    println!(
        "  Average rate: {:.1} upserts/s, {:.1} records/s",
        (us_upserts + eu_upserts) as f64 / elapsed_secs,
        (us_records + eu_records) as f64 / elapsed_secs
    );

    Ok(())
}
