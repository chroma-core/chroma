---
title: OpenAI
---

import { Callout } from '/snippets/callout.mdx';

Chroma provides a convenient wrapper around OpenAI's embedding API. This embedding function runs remotely on OpenAI's servers, and requires an API key. You can get an API key by signing up for an account at [OpenAI](https://openai.com/api/).
By default, the wrapper checks `OPENAI_API_KEY` envionment variable for the API key. Optionally, you can pass in the API key directly.

The following OpenAI Embedding Models are supported:

- `text-embedding-ada-002`
- `text-embedding-3-small`
- `text-embedding-3-large`


<Callout>
Visit OpenAI Embeddings [documentation](https://platform.openai.com/docs/guides/embeddings) for more information.
</Callout>

<Tabs>
<Tab title="Python" icon="python">

This embedding function relies on the `openai` python package, which you can install with `pip install openai`.

You can pass in an optional `model_name` argument, which lets you choose which OpenAI embeddings model to use. By default, Chroma uses `text-embedding-ada-002`.

```python
import chromadb.utils.embedding_functions as embedding_functions
openai_ef = embedding_functions.OpenAIEmbeddingFunction(
    api_key_env_var="OPENAI_API_KEY",
    model_name="text-embedding-3-small"
)
```

To use the OpenAI embedding models on other platforms such as Azure, you can use the `api_base` and `api_type` parameters:

```python
import chromadb.utils.embedding_functions as embedding_functions
openai_ef = embedding_functions.OpenAIEmbeddingFunction(
    api_key_env_var="OPENAI_API_KEY",
    api_base="YOUR_API_BASE_PATH",
    api_type="azure",
    api_version="YOUR_API_VERSION",
    model_name="text-embedding-3-small"
)
```

</Tab>

<Tab title="TypeScript" icon="js">

You can pass in an optional `model` argument, which lets you choose which OpenAI embeddings model to use. By default, Chroma uses `text-embedding-3-small`.

```typescript
// npm install @chroma-core/openai

import { OpenAIEmbeddingFunction } from "@chroma-core/openai";

const embeddingFunction = new OpenAIEmbeddingFunction({
    modelName: "text-embedding-3-small",
});

// use directly
const embeddings = embeddingFunction.generate(["document1", "document2"]);

// pass documents to query for .add and .query
let collection = await client.createCollection({
    name: "name",
    embeddingFunction: embeddingFunction,
});
collection = await client.getCollection({
    name: "name",
    embeddingFunction: embeddingFunction,
});
```

To supply the API key directly

```typescript
const embeddingFunction = new OpenAIEmbeddingFunction({
    modelName: "text-embedding-3-small",
    apiKey: "YOUR_API_KEY",
});
```

To use the OpenAI embedding models on other platforms such as GitHub AI Model, you can supply the endpoint through the `apiBase` parameter:

```typescript
import { OpenAIEmbeddingFunction } from "@chroma-core/openai";

const embeddingFunction = new OpenAIEmbeddingFunction({
    modelName: "openai/text-embedding-3-small", // GitHub uses provider prefix for model names
    apiBase: "https://models.github.ai/inference"
});
```

</Tab>

</Tabs>
